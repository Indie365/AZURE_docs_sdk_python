### YamlMime:PythonClass
uid: azure.mgmt.media.models.AudioAnalyzerPreset
name: AudioAnalyzerPreset
fullName: azure.mgmt.media.models.AudioAnalyzerPreset
module: azure.mgmt.media.models
inheritances:
- azure.mgmt.media.models._models_py3.Preset
summary: 'The Audio Analyzer preset applies a pre-defined set of AI-based analysis
  operations, including speech transcription. Currently, the preset supports processing
  of content with a single audio track.


  You probably want to use the sub-classes and not this class directly. Known sub-classes
  are:

  VideoAnalyzerPreset


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'AudioAnalyzerPreset(*, audio_language: str | None = None, mode: str | _models.AudioAnalysisMode
    | None = None, experimental_options: Dict[str, str] | None = None, **kwargs)'
  parameters:
  - name: audio_language
    description: 'The language for the audio payload in the input using the BCP-47

      format of ''language tag-region'' (e.g: ''en-US'').  If you know the language
      of your content, it

      is recommended that you specify it. The language must be specified explicitly
      for

      AudioAnalysisMode::Basic, since automatic language detection is not included
      in basic mode. If

      the language isn''t specified or set to null, automatic language detection will
      choose the first

      language detected and process with the selected language for the duration of
      the file. It does

      not currently support dynamically switching between languages after the first
      language is

      detected. The automatic detection works best with audio recordings with clearly
      discernable

      speech. If automatic detection fails to find the language, transcription would
      fallback to

      ''en-US''." The list of supported languages is available here:

      https://go.microsoft.com/fwlink/?linkid=2109463.'
    types:
    - <xref:str>
  - name: mode
    description: 'Determines the set of audio analysis operations to be performed.
      If unspecified,

      the Standard AudioAnalysisMode would be chosen. Known values are: "Standard"
      and "Basic".'
    types:
    - <xref:str>
    - <xref:azure.mgmt.media.models.AudioAnalysisMode>
  - name: experimental_options
    description: 'Dictionary containing key value pairs for parameters not exposed

      in the preset itself.'
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
variables:
- description: The discriminator for derived types. Required.
  name: odata_type
  types:
  - <xref:str>
- description: 'The language for the audio payload in the input using the BCP-47 format

    of ''language tag-region'' (e.g: ''en-US'').  If you know the language of your
    content, it is

    recommended that you specify it. The language must be specified explicitly for

    AudioAnalysisMode::Basic, since automatic language detection is not included in
    basic mode. If

    the language isn''t specified or set to null, automatic language detection will
    choose the first

    language detected and process with the selected language for the duration of the
    file. It does

    not currently support dynamically switching between languages after the first
    language is

    detected. The automatic detection works best with audio recordings with clearly
    discernable

    speech. If automatic detection fails to find the language, transcription would
    fallback to

    ''en-US''." The list of supported languages is available here:

    https://go.microsoft.com/fwlink/?linkid=2109463.'
  name: audio_language
  types:
  - <xref:str>
- description: 'Determines the set of audio analysis operations to be performed. If
    unspecified,

    the Standard AudioAnalysisMode would be chosen. Known values are: "Standard" and
    "Basic".'
  name: mode
  types:
  - <xref:str>
  - <xref:azure.mgmt.media.models.AudioAnalysisMode>
- description: 'Dictionary containing key value pairs for parameters not exposed in

    the preset itself.'
  name: experimental_options
  types:
  - <xref:dict>[<xref:str>, <xref:str>]
methods:
- uid: azure.mgmt.media.models.AudioAnalyzerPreset.as_dict
  name: as_dict
  summary: "Return a dict that can be JSONify using json.dump.\n\nAdvanced usage might\
    \ optionally use a callback as parameter:\n\nKey is the attribute name used in\
    \ Python. Attr_desc\nis a dict of metadata. Currently contains 'type' with the\n\
    msrest type and 'key' with the RestAPI encoded key.\nValue is the current value\
    \ in this object.\n\nThe string returned will be used to serialize the key.\n\
    If the return type is a list, this is considered hierarchical\nresult dict.\n\n\
    See the three examples in this file:\n\n* attribute_transformer \n\n* full_restapi_key_transformer\
    \ \n\n* last_restapi_key_transformer \n\nIf you want XML serialization, you can\
    \ pass the kwargs is_xml=True."
  signature: as_dict(keep_readonly=True, key_transformer=<function attribute_transformer>,
    **kwargs)
  parameters:
  - name: key_transformer
    description: A key transformer function.
    types:
    - <xref:function>
  - name: keep_readonly
    defaultValue: 'True'
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.mgmt.media.models.AudioAnalyzerPreset.deserialize
  name: deserialize
  summary: Parse a str using the RestAPI syntax and return a model.
  signature: deserialize(data, content_type=None)
  parameters:
  - name: data
    description: A str using RestAPI structure. JSON by default.
    isRequired: true
    types:
    - <xref:str>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.mgmt.media.models.AudioAnalyzerPreset.enable_additional_properties_sending
  name: enable_additional_properties_sending
  signature: enable_additional_properties_sending()
- uid: azure.mgmt.media.models.AudioAnalyzerPreset.from_dict
  name: from_dict
  summary: 'Parse a dict using given key extractor return a model.


    By default consider key

    extractors (rest_key_case_insensitive_extractor, attribute_key_case_insensitive_extractor

    and last_rest_key_case_insensitive_extractor)'
  signature: from_dict(data, key_extractors=None, content_type=None)
  parameters:
  - name: data
    description: A dict using RestAPI structure
    isRequired: true
    types:
    - <xref:dict>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  - name: key_extractors
    defaultValue: None
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.mgmt.media.models.AudioAnalyzerPreset.is_xml_model
  name: is_xml_model
  signature: is_xml_model()
- uid: azure.mgmt.media.models.AudioAnalyzerPreset.serialize
  name: serialize
  summary: 'Return the JSON that would be sent to azure from this model.


    This is an alias to *as_dict(full_restapi_key_transformer, keep_readonly=False)*.


    If you want XML serialization, you can pass the kwargs is_xml=True.'
  signature: serialize(keep_readonly=False, **kwargs)
  parameters:
  - name: keep_readonly
    description: If you want to serialize the readonly attributes
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
